{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dca2a1b",
   "metadata": {},
   "source": [
    "# EmotiVoice: An Intelligent Voice Assistant with Emotion Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009d4ea9",
   "metadata": {},
   "source": [
    "**Author:** Jai Kumar\n",
    "\n",
    "**Course:** EXC Project  \n",
    "**Date:** April 13, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d8a110",
   "metadata": {},
   "source": [
    "## Index\n",
    "1. Problem Statement\n",
    "2. Introduction\n",
    "3. Literature Review\n",
    "4. Bill of Materials/Software Used\n",
    "5. Implementation\n",
    "6. Proof of Concept\n",
    "7. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b259fe",
   "metadata": {},
   "source": [
    "## 1. Problem Statement\n",
    "Design and implement a software-only intelligent voice assistant that can detect user emotions from both voice tone and spoken text, providing emotionally-aware responses. This solution should require no external hardware and be executable on a personal computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641911e2",
   "metadata": {},
   "source": [
    "## 2. Introduction\n",
    "Voice assistants have become widely adopted, yet most lack emotional intelligence. EmotiVoice bridges this gap using AI-based emotion detection through speech tone and sentiment analysis. This enhances interactivity and allows the assistant to respond in a more empathetic manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a84b8e",
   "metadata": {},
   "source": [
    "## 3. Literature Review\n",
    "- Pretrained models like `Wav2Vec2` and libraries like `TextBlob` make emotion recognition more accessible.\n",
    "- Tools like HuggingFace and pyttsx3 help build robust, interactive assistants.\n",
    "- Past research on RAVDESS dataset and sentiment analysis via NLP has proven emotional indicators from voice and text are highly correlated with intent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0460af2b",
   "metadata": {},
   "source": [
    "## 4. Bill of Materials / Software Used\n",
    "- Python 3.10+\n",
    "- `speech_recognition`\n",
    "- `pyttsx3`\n",
    "- `textblob`\n",
    "- `transformers`\n",
    "- `torch`\n",
    "- `torchaudio`\n",
    "- `Tkinter`\n",
    "- `librosa`\n",
    "- Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d23d76e",
   "metadata": {},
   "source": [
    "## 5. Implementation\n",
    "The implementation consists of several modules:\n",
    "- Speech Recognition using Google API\n",
    "- Text Sentiment Detection using TextBlob\n",
    "- Voice Tone Emotion Detection using `HuggingFace`\n",
    "- Text-to-Speech using pyttsx3\n",
    "- GUI with Tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a4a143-309e-4be0-b18a-469f1cfbb3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Snippets\n",
    "```\n",
    "python\n",
    "import speech_recognition as sr\n",
    "from textblob import TextBlob\n",
    "import pyttsx3\n",
    "import random\n",
    "\n",
    "# ------------------------\n",
    "# 1. Speech Recognition\n",
    "# ------------------------\n",
    "recognizer = sr.Recognizer()\n",
    "mic = sr.Microphone()\n",
    "\n",
    "print(\"\\n[1] Listening for your voice input...\")\n",
    "with mic as source:\n",
    "    recognizer.adjust_for_ambient_noise(source)\n",
    "    audio = recognizer.listen(source)\n",
    "\n",
    "try:\n",
    "    text = recognizer.recognize_google(audio)\n",
    "    print(f\"\\nRecognized Text: {text}\")\n",
    "\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Sorry, could not understand your speech.\")\n",
    "    exit()\n",
    "except sr.RequestError as e:\n",
    "    print(f\"Could not request results; {e}\")\n",
    "    exit()\n",
    "\n",
    "# ------------------------\n",
    "# 2. Sentiment Analysis\n",
    "# ------------------------\n",
    "print(\"\\n[2] Running Sentiment Analysis...\")\n",
    "blob = TextBlob(text)\n",
    "polarity = blob.sentiment.polarity\n",
    "subjectivity = blob.sentiment.subjectivity\n",
    "print(f\"Polarity: {polarity}\")\n",
    "print(f\"Subjectivity: {subjectivity}\")\n",
    "\n",
    "# ------------------------\n",
    "# 3. Text to Speech Output\n",
    "# ------------------------\n",
    "print(\"\\n[3] Responding with TTS...\")\n",
    "tts = pyttsx3.init()\n",
    "response = \"It's 11:04 PM\"\n",
    "tts.say(response)\n",
    "tts.runAndWait()\n",
    "print(f\"Spoken Output: {response}\")\n",
    "\n",
    "# ------------------------\n",
    "# 4. Mock Emotion Detection (based on sentiment)\n",
    "# ------------------------\n",
    "print(\"\\n[4] Detecting Emotion...\")\n",
    "if polarity > 0.6:\n",
    "    emotion = \"Happy\"\n",
    "elif polarity < -0.4:\n",
    "    emotion = \"Angry\"\n",
    "elif 0.1 < polarity <= 0.6:\n",
    "    emotion = \"Content\"\n",
    "else:\n",
    "    emotion = \"Neutral\"\n",
    "\n",
    "print(f\"Final Emotion Detected: {emotion}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab262af-95fa-4beb-a367-840f0665a727",
   "metadata": {},
   "source": [
    "![Mock GUI](mainoutput.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf7cbc1",
   "metadata": {},
   "source": [
    "## 6. Proof of Concept\n",
    "The assistant was tested with multiple sentences and tone samples. Below are screenshots from the working GUI:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cdab9976",
   "metadata": {},
   "source": [
    "![Mock GUI](mainoutput2.png)\n",
    "![Mock GUI](mainoutput3.png)\n",
    "\n",
    "*Figure 1: GUI Displaying Emotion and Response*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76fbfd6",
   "metadata": {},
   "source": [
    "## 7. References\n",
    "- https://textblob.readthedocs.io/en/dev/\n",
    "- https://realpython.com/python-speech-recognition/\n",
    "- https://pypi.org/project/pyttsx3/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
